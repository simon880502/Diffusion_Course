{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c98c44-0505-43b2-957c-86aa4d0e621e",
   "metadata": {
    "id": "a1c98c44-0505-43b2-957c-86aa4d0e621e"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qk4Uw_iSr3Mc",
   "metadata": {
    "id": "Qk4Uw_iSr3Mc"
   },
   "source": [
    "<br>\n",
    "\n",
    "# <font color=\"#76b900\">**Notebook 7:**Â ä½¿ç”¨å‘é‡å­˜å„²åº«(Vector Store)çš„æª¢ç´¢å¢å¼·ç”Ÿæˆ(Retrieval-Augmented Generation)</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "åœ¨å‰ä¸€å€‹ notebook ä¸­ï¼Œæˆ‘å€‘å­¸ç¿’äº†å…§åµŒæ¨¡å‹(Embedding Models)ä¸¦ç·´ç¿’äº†å®ƒå€‘çš„ä¸€äº›åŠŸèƒ½ã€‚æˆ‘å€‘è¨è«–äº†å®ƒå€‘åœ¨é•·ç¯‡çš„(long-form)æ–‡ä»¶æ¯”è¼ƒçš„é æœŸä½¿ç”¨æ¡ˆä¾‹ï¼Œä¸¦æ‰¾åˆ°äº†å°‡å…¶ä½œç‚ºè‡ªè¨‚èªç¾©æ¯”è¼ƒ(custom semantic comparisons)éª¨å¹¹çš„æ–¹æ³•ã€‚é€™å€‹ notebook å°‡é€²ä¸€æ­¥æ¨é€²å°‡é€™äº›æƒ³æ³•æœå‘æª¢ç´¢(Retrieval)æ¨¡å‹çš„é æœŸä½¿ç”¨æ¡ˆä¾‹ï¼Œä¸¦æ¢ç´¢å¦‚ä½•å»ºæ§‹ä¾è³´*å‘é‡å­˜å„²åº«(Vector Store)*ä¾†è‡ªå‹•ä¿å­˜å’Œæª¢ç´¢(Retrieval)è³‡è¨Šçš„èŠå¤©æ©Ÿå™¨äººç³»çµ±ã€‚\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### **å­¸ç¿’ç›®æ¨™ï¼š**\n",
    "\n",
    "-   äº†è§£èªç¾©ç›¸ä¼¼æ€§æ”¯æ´çš„ç³»çµ±å¦‚ä½•ä¿ƒé€²æ˜“æ–¼ä½¿ç”¨çš„æª¢ç´¢(Retrieval)åˆ¶å®šã€‚\n",
    "-   å­¸ç¿’å¦‚ä½•å°‡æª¢ç´¢(Retrieval)æ¨¡çµ„æ•´åˆåˆ°æ‚¨çš„èŠå¤©æ¨¡å‹ç³»çµ±ä¸­ï¼Œç”¨æ–¼æª¢ç´¢å¢å¼·ç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ç®¡ç·š(Pipeline)ï¼Œé€™å¯ä»¥æ‡‰ç”¨æ–¼æ–‡ä»¶æª¢ç´¢(Retrieval)å’Œå°è©±è¨˜æ†¶(conversation memory)ç·©è¡å€ç­‰ä»»å‹™ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "### **å€¼å¾—æ€è€ƒçš„å•é¡Œï¼š**\n",
    "\n",
    "\n",
    "-   é€™å€‹ notebook ä¸å˜—è©¦æ•´åˆéšå±¤çµæ§‹(Hierarchy)åˆ†ææ¨ç†(Reasoning)æˆ–å¯¦ç”¨çš„(non-naive) RAGï¼ˆå¦‚è¦åŠƒ Agentï¼‰ã€‚è€ƒæ…®éœ€è¦ä»€éº¼ä¿®æ”¹æ‰èƒ½ä½¿é€™äº›çµ„ä»¶åœ¨ LCEL éˆ(Chain)ä¸­é‹ä½œã€‚\n",
    "-   è€ƒæ…®ä½•æ™‚æœ€å¥½å°‡æ‚¨çš„å‘é‡å­˜å„²åº«(Vector Store)è§£æ±ºæ–¹æ¡ˆç§»è‡³å¯æ“´å±•æœå‹™ï¼Œä»¥åŠä½•æ™‚ GPU å°æ–¼æœ€ä½³åŒ–è®Šå¾—å¿…è¦ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "### **ç’°å¢ƒè¨­ç½®ï¼š**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5XmeiiOWtuxC",
   "metadata": {
    "id": "5XmeiiOWtuxC"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "## ^^ Comment out if you want to see the pip install process\n",
    "\n",
    "## Necessary for Colab, not necessary for course environment\n",
    "# %pip install -q langchain langchain-nvidia-ai-endpoints gradio rich\n",
    "# %pip install -q arxiv pymupdf faiss-cpu\n",
    "\n",
    "## If you encounter a typing-extensions issue, restart your runtime and try again\n",
    "# from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "# ChatNVIDIA.get_available_models()\n",
    "\n",
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37fe234-2bdb-4107-8483-efda9aa5e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ced9b0-30ed-4ccc-936f-ca03d6e172bf",
   "metadata": {
    "id": "a3ced9b0-30ed-4ccc-936f-ca03d6e172bf"
   },
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬ä¸€éƒ¨åˆ†ï¼š**Â RAG å·¥ä½œæµç¨‹æ‘˜è¦\n",
    "\n",
    "\n",
    "é€™å€‹ notebook å°‡æ¢ç´¢å¹¾å€‹ä½œæ³•(Paradigm)ä¸¦æ¨å°åƒè€ƒç¨‹å¼ç¢¼ï¼Œå¹«åŠ©æ‚¨è™•ç†ä¸€äº›æœ€å¸¸è¦‹(popular)çš„æª¢ç´¢å¢å¼·(Retrieval-Augmented)å·¥ä½œæµç¨‹ã€‚å…·é«”ä¾†èªªï¼Œå°‡æ¶µè“‹ä»¥ä¸‹éƒ¨åˆ†ï¼ˆä¸¦çªå‡ºå·®ç•°ï¼‰ï¼š\n",
    "\n",
    "> ***å°è©±äº¤æµçš„å‘é‡å­˜å„²åº«(Vector Store)å·¥ä½œæµç¨‹ï¼š***\n",
    "\n",
    "-   ç‚ºæ¯å€‹æ–°å°è©±ç”Ÿæˆèªç¾©å…§åµŒ(Embedding)ã€‚\n",
    "\n",
    "-   å°‡è¨Šæ¯ä¸»é«”æ·»åŠ åˆ°å‘é‡å­˜å„²åº«(Vector Store)ä»¥ä¾›æª¢ç´¢(Retrieval)ã€‚\n",
    "\n",
    "-   æŸ¥è©¢å‘é‡å­˜å„²åº«(Vector Store)ä»¥ç²å–ç›¸é—œè¨Šæ¯ä¾†å¡«å…… LLM è„ˆçµ¡è³‡è¨Š(Context)ã€‚\n",
    "\n",
    "> ***ä»»æ„æ–‡ä»¶çš„ä¿®æ”¹å·¥ä½œæµç¨‹ï¼š***\n",
    "\n",
    "-   **å°‡æ–‡ä»¶åˆ†å‰²æˆåˆ†å¡Š(Chunking)ä¸¦è™•ç†æˆæœ‰ç”¨çš„è¨Šæ¯ã€‚**\n",
    "\n",
    "-   ç‚ºæ¯å€‹**æ–°æ–‡ä»¶åˆ†å¡Š**ç”Ÿæˆèªç¾©å…§åµŒ(Embedding)ã€‚\n",
    "\n",
    "-   å°‡**åˆ†å¡Šä¸»é«”**æ·»åŠ åˆ°å‘é‡å­˜å„²åº«(Vector Store)ä»¥ä¾›æª¢ç´¢(Retrieval)ã€‚\n",
    "\n",
    "-   æŸ¥è©¢å‘é‡å­˜å„²åº«(Vector Store)ä»¥ç²å–ç›¸é—œ**åˆ†å¡Š**ä¾†å¡«å…… LLM è„ˆçµ¡è³‡è¨Š(Context)ã€‚\n",
    "\n",
    "    -   ***å¯é¸ï¼š*Â ä¿®æ”¹/ç¶œåˆçµæœ(Synthesis)ä»¥ç²å¾—æ›´å¥½çš„ LLM çµæœã€‚**\n",
    "\n",
    "> **ä»»æ„æ–‡ä»¶ç›®éŒ„çš„æ“´å±•å·¥ä½œæµç¨‹ï¼š**\n",
    "\n",
    "-   å°‡**æ¯å€‹æ–‡ä»¶**åˆ†å‰²æˆåˆ†å¡Š(Chunking)ä¸¦è™•ç†æˆæœ‰ç”¨çš„è¨Šæ¯ã€‚\n",
    "\n",
    "-   ç‚ºæ¯å€‹æ–°æ–‡ä»¶åˆ†å¡Šç”Ÿæˆèªç¾©å…§åµŒ(Embedding)ã€‚\n",
    "\n",
    "-   å°‡åˆ†å¡Šä¸»é«”æ·»åŠ åˆ° **å¯æ“´å±•çš„å‘é‡è³‡æ–™åº«ä»¥é€²è¡Œå¿«é€Ÿæª¢ç´¢(Retrieval)** ã€‚\n",
    "\n",
    "    -   ***å¯é¸ï¼š*Â åˆ©ç”¨éšå±¤çµæ§‹(Hierarchy)æˆ–ä¸­ä»‹è³‡æ–™(Metadata)çµæ§‹ä¾†è™•ç†æ›´å¤§çš„ç³»çµ±ã€‚**\n",
    "\n",
    "-   æŸ¥è©¢**å‘é‡è³‡æ–™åº«**ä»¥ç²å–ç›¸é—œåˆ†å¡Šä¾†å¡«å…… LLM è„ˆçµ¡è³‡è¨Š(Context)ã€‚\n",
    "\n",
    "    -   *å¯é¸ï¼š*Â ä¿®æ”¹/ç¶œåˆçµæœ(Synthesis)ä»¥ç²å¾—æ›´å¥½çš„ LLM çµæœã€‚\n",
    "\n",
    "åœç¹ RAG çš„ä¸€äº›æœ€é‡è¦è¡“èªåœ¨Â [**LlamaIndex æ¦‚å¿µé é¢**](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html)Â ä¸­æœ‰è©³ç´°ä»‹ç´¹ï¼Œé€™æœ¬èº«å°±æ˜¯é‡å° LlamaIndex è¼‰å…¥å’Œæª¢ç´¢(Retrieval)ç­–ç•¥é€²å±•çš„çµ•ä½³èµ·é»ã€‚æˆ‘å€‘å¼·çƒˆå»ºè­°æ‚¨åœ¨ç¹¼çºŒé€™å€‹ notebook æ™‚å°‡å…¶ä½œç‚ºåƒè€ƒï¼Œä¸¦å»ºè­°æ‚¨åœ¨èª²ç¨‹çµæŸå¾Œå˜—è©¦ LlamaIndexï¼Œä»¥è¦ªèº«è€ƒæ…®å…¶å„ªç¼ºé»ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1911b-a6a2-47c5-bc66-1b61e6516437",
   "metadata": {
    "id": "baa1911b-a6a2-47c5-bc66-1b61e6516437"
   },
   "source": [
    "<!-- > <img src=\"https://drive.google.com/uc?export=view&id=1cFbKbVvLLnFPs3yWCKIuzXkhBWh6nLQY\" width=1200px/> -->\n",
    "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/data_connection_langchain.jpeg\" width=1200px/>\n",
    ">\n",
    "> ä¾†è‡ªÂ  [**Retrieval | LangChain**ğŸ¦œï¸ğŸ”—](https://python.langchain.com/v0.1/docs/modules/data_connection/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XaZ20XoeSTD-",
   "metadata": {
    "id": "XaZ20XoeSTD-"
   },
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬äºŒéƒ¨åˆ†ï¼š**Â å°è©±æ­·å²ç´€éŒ„(History)çš„ RAG\n",
    "\n",
    "\n",
    "åœ¨æˆ‘å€‘ä¹‹å‰çš„æ¢ç´¢ä¸­ï¼Œæˆ‘å€‘æ·±å…¥ç ”ç©¶äº†æ–‡ä»¶å…§åµŒæ¨¡å‹(Embedding Models)çš„åŠŸèƒ½ï¼Œä¸¦ä½¿ç”¨å®ƒå€‘ä¾†å…§åµŒ(Embedding)ã€å„²å­˜å’Œæ¯”è¼ƒæ–‡å­—(Text)çš„èªç¾©å‘é‡è¡¨ç¤ºã€‚é›–ç„¶æˆ‘å€‘å¯ä»¥æ€è€ƒå¦‚ä½•æ‰‹å‹•æœ‰æ•ˆåœ°å°‡å…¶æ“´å±•åˆ°å‘é‡å­˜å„²åº«(Vector Store)é ˜åŸŸï¼Œä½†ä½¿ç”¨æ¨™æº– API çš„çœŸæ­£ç¾å¦™ä¹‹è™•åœ¨æ–¼å®ƒèˆ‡å…¶ä»–å·²ç¶“å¯ä»¥ç‚ºæˆ‘å€‘åšç¹é‡å·¥ä½œçš„æ¡†æ¶çš„å¼·åŠ›æ•´åˆï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LRx0XUf_Sdxw",
   "metadata": {
    "id": "LRx0XUf_Sdxw"
   },
   "source": [
    "### **æ­¥é©Ÿ 1**ï¼šç²å¾—å°è©±\n",
    "\n",
    "\n",
    "è€ƒæ…®ä¸€å€‹ä½¿ç”¨ Llama-13B åœ¨èŠå¤© Agent å’Œåç‚º Beras çš„è—ç†Šä¹‹é–“è£½ä½œçš„å°è©±ã€‚é€™å€‹å°è©±å……æ»¿äº†ç´°ç¯€å’Œæ½›åœ¨çš„åˆ†æ­§ï¼Œç‚ºæˆ‘å€‘çš„ç ”ç©¶æä¾›äº†è±å¯Œçš„è³‡æ–™é›†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "IUfCuMkoShWI",
   "metadata": {
    "id": "IUfCuMkoShWI"
   },
   "outputs": [],
   "source": [
    "conversation = [  ## This conversation was generated partially by an AI system, and modified to exhibit desirable properties\n",
    "    \"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the rocky mountains?\",\n",
    "    \"[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch across North America\",\n",
    "    \"[Beras] Wow, that sounds amazing! Ive never been to the Rocky Mountains before, but Ive heard many great things about them.\",\n",
    "    \"[Agent] I hope you get to visit them someday, Beras! It would be a great adventure for you!\"\n",
    "    \"[Beras] Thank you for the suggestion! Ill definitely keep it in mind for the future.\",\n",
    "    \"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research online or watching documentaries about them.\"\n",
    "    \"[Beras] I live in the arctic, so I'm not used to the warm climate there. I was just curious, ya know!\",\n",
    "    \"[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains and their significance!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tDL2tAo2Skh2",
   "metadata": {
    "id": "tDL2tAo2Skh2"
   },
   "source": [
    "\n",
    "ä½¿ç”¨å‰ä¸€å€‹ notebook çš„æ‰‹å‹•å…§åµŒ(Embedding)ç­–ç•¥ä»ç„¶éå¸¸å¯è¡Œï¼Œä½†æˆ‘å€‘ä¹Ÿå¯ä»¥æ”¾å¿ƒè®“**å‘é‡å­˜å„²åº«(Vector Store)**ç‚ºæˆ‘å€‘å®Œæˆæ‰€æœ‰å·¥ä½œï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5hIp943mSqGZ",
   "metadata": {
    "id": "5hIp943mSqGZ"
   },
   "source": [
    "### **æ­¥é©Ÿ 2ï¼š**Â å»ºæ§‹æˆ‘å€‘çš„å‘é‡å­˜å„²åº«(Vector Store)æª¢ç´¢å™¨\n",
    "\n",
    "\n",
    "ç‚ºäº†ç°¡åŒ–å°æˆ‘å€‘å°è©±çš„ç›¸ä¼¼æ€§æŸ¥è©¢ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨å‘é‡å­˜å„²åº«(Vector Store)ä¾†å¹«åŠ©æˆ‘å€‘è¿½è¹¤æ®µè½ï¼ **å‘é‡å­˜å„²åº«(Vector Store)** ï¼Œæˆ–å‘é‡å„²å­˜ç³»çµ±ï¼ŒæŠ½è±¡åŒ–äº†å…§åµŒ(Embedding)/æ¯”è¼ƒç­–ç•¥çš„å¤§éƒ¨åˆ†ä½éšç´°ç¯€ï¼Œä¸¦æä¾›äº†ä¸€å€‹ç°¡å–®çš„ä»‹é¢ä¾†è¼‰å…¥å’Œæ¯”è¼ƒå‘é‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pnaOBgexS-kp",
   "metadata": {
    "id": "pnaOBgexS-kp"
   },
   "source": [
    "<!-- > <img src=\"https://drive.google.com/uc?export=view&id=1ZjwYbSZzsXK6ZP8O1-cY3BeRffV4oqzb\" width=1000px/> -->\n",
    "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/vector_stores.jpeg\" width=1200px/>\n",
    ">\n",
    "> ä¾†è‡ª [**Vector Stores | LangChain**ğŸ¦œï¸ğŸ”—](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DwZUh6kgS5Ki",
   "metadata": {
    "id": "DwZUh6kgS5Ki"
   },
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "é™¤äº†å¾ API è§’åº¦ç°¡åŒ–æµç¨‹å¤–ï¼Œå‘é‡å­˜å„²åº«(Vector Store)é‚„åœ¨åº•å±¤å¯¦ä½œé€£æ¥å™¨(Connector)ã€æ•´åˆå’Œæœ€ä½³åŒ–ã€‚åœ¨æˆ‘å€‘çš„æƒ…æ³ä¸‹ï¼Œæˆ‘å€‘å°‡å¾Â [**FAISS å‘é‡å­˜å„²åº«(Vector Store)**](https://python.langchain.com/docs/integrations/vectorstores/faiss)Â é–‹å§‹ï¼Œå®ƒå°‡ LangChain ç›¸å®¹çš„å…§åµŒæ¨¡å‹(Embedding Model)èˆ‡Â [**FAISS (Facebook AI Similarity Search)**](https://github.com/facebookresearch/faiss)Â å‡½å¼åº«(library)æ•´åˆï¼Œä½¿æµç¨‹åœ¨æˆ‘å€‘çš„æœ¬åœ°æ©Ÿå™¨ä¸Šå¿«é€Ÿä¸”å¯æ“´å±•ï¼\n",
    "\n",
    "**å…·é«”ä¾†èªªï¼š**\n",
    "\n",
    "1.  æˆ‘å€‘å¯ä»¥é€éÂ `from_texts`Â å»ºæ§‹å‡½å¼(function)å°‡æˆ‘å€‘çš„å°è©±é¤µçµ¦Â [**FAISS å‘é‡å­˜å„²åº«(Vector Store)**](https://python.langchain.com/docs/integrations/vectorstores/faiss)ã€‚é€™å°‡å–å¾—æˆ‘å€‘çš„å°è©±è³‡æ–™å’Œå…§åµŒæ¨¡å‹(Embedding Model)ä¾†å‰µå»ºä¸€å€‹å¯æœå°‹çš„è¨è«–ç´¢å¼•ã€‚\n",
    "\n",
    "2.  ç„¶å¾Œé€™å€‹å‘é‡å­˜å„²åº«(Vector Store)å¯ä»¥è¢«ã€Œè§£é‡‹ã€ç‚ºæª¢ç´¢å™¨ï¼Œæ”¯æ´ LangChain å¯é‹è¡Œç‰©ä»¶(Runnable) API ä¸¦è¿”å›é€éè¼¸å…¥(Intake)æŸ¥è©¢æª¢ç´¢(Retrieval)çš„æ–‡ä»¶ã€‚\n",
    "\n",
    "ä»¥ä¸‹é¡¯ç¤ºäº†å¦‚ä½•ä½¿ç”¨ LangChainÂ `vectorstore`Â API å»ºæ§‹ FAISS å‘é‡å­˜å„²åº«(Vector Store)ä¸¦å°‡å…¶é‡æ–°è§£é‡‹ç‚ºæª¢ç´¢å™¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1kE2-ejoTKKU",
   "metadata": {
    "id": "1kE2-ejoTKKU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 240 ms, sys: 276 ms, total: 516 ms\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## ^^ This cell will be timed to see how long the conversation embedding takes\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "## Streamlined from_texts FAISS vectorstore construction from text list\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "retriever = convstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muN66v5PW5dW",
   "metadata": {
    "id": "muN66v5PW5dW"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "æª¢ç´¢å™¨ç¾åœ¨å¯ä»¥åƒä»»ä½•å…¶ä»– LangChain å¯é‹è¡Œç‰©ä»¶(Runnable)ä¸€æ¨£ä½¿ç”¨ï¼Œä¾†æŸ¥è©¢å‘é‡å­˜å„²åº«(Vector Store)ä»¥ç²å–ä¸€äº›ç›¸é—œæ–‡ä»¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "kNZJTnlEWVYh",
   "metadata": {
    "id": "kNZJTnlEWVYh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'13857896-6042-4742-981c-91c71ed6a8bc'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rocky mountains?\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ac0298ae-bbad-4673-8ac5-d4fae1b64aeb'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and their significance!'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'5e0cce51-85b1-452f-ab69-b9a3ed3c7de4'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] I hope you get to visit them someday, Beras! It would be a great adventure for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">you![Beras] Thank you for the suggestion! Ill definitely keep it in mind for the future.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'c1ad2694-8c27-4289-b4ed-190814323f38'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">online or watching documentaries about them.[Beras] I live in the arctic, so I'm not used to the warm climate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">there. I was just curious, ya know!\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'13857896-6042-4742-981c-91c71ed6a8bc'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the \u001b[0m\n",
       "\u001b[32mrocky mountains?\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'ac0298ae-bbad-4673-8ac5-d4fae1b64aeb'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Absolutely! Lets continue the conversation and explore more about the Rocky Mountains\u001b[0m\n",
       "\u001b[32mand their significance!'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'5e0cce51-85b1-452f-ab69-b9a3ed3c7de4'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I hope you get to visit them someday, Beras! It would be a great adventure for \u001b[0m\n",
       "\u001b[32myou!\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Thank you for the suggestion! Ill definitely keep it in mind for the future.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'c1ad2694-8c27-4289-b4ed-190814323f38'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In the meantime, you can learn more about the Rocky Mountains by doing some research \u001b[0m\n",
       "\u001b[32monline or watching documentaries about them.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I live in the arctic, so I'm not used to the warm climate \u001b[0m\n",
       "\u001b[32mthere. I was just curious, ya know!\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(retriever.invoke(\"What is your name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "SE1eDZTEWScC",
   "metadata": {
    "id": "SE1eDZTEWScC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'51cccb61-374e-44be-94da-e03171e5c42d'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across North America'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'c1ad2694-8c27-4289-b4ed-190814323f38'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">online or watching documentaries about them.[Beras] I live in the arctic, so I'm not used to the warm climate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">there. I was just curious, ya know!\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'13857896-6042-4742-981c-91c71ed6a8bc'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rocky mountains?\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ac0298ae-bbad-4673-8ac5-d4fae1b64aeb'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and their significance!'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'51cccb61-374e-44be-94da-e03171e5c42d'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m The Rocky Mountains are a beautiful and majestic range of mountains that stretch \u001b[0m\n",
       "\u001b[32macross North America'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'c1ad2694-8c27-4289-b4ed-190814323f38'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In the meantime, you can learn more about the Rocky Mountains by doing some research \u001b[0m\n",
       "\u001b[32monline or watching documentaries about them.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I live in the arctic, so I'm not used to the warm climate \u001b[0m\n",
       "\u001b[32mthere. I was just curious, ya know!\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'13857896-6042-4742-981c-91c71ed6a8bc'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the \u001b[0m\n",
       "\u001b[32mrocky mountains?\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'ac0298ae-bbad-4673-8ac5-d4fae1b64aeb'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Absolutely! Lets continue the conversation and explore more about the Rocky Mountains\u001b[0m\n",
       "\u001b[32mand their significance!'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(retriever.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mtNCEXLYTVf4",
   "metadata": {
    "id": "mtNCEXLYTVf4"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "å¦‚æˆ‘å€‘æ‰€è¦‹ï¼Œæˆ‘å€‘çš„æª¢ç´¢å™¨å¾æˆ‘å€‘çš„æŸ¥è©¢ä¸­æ‰¾åˆ°äº†ä¸€äº›èªç¾©ç›¸é—œçš„æ–‡ä»¶ã€‚æ‚¨å¯èƒ½æœƒæ³¨æ„åˆ°ä¸¦éæ‰€æœ‰æ–‡ä»¶éƒ½æœ‰ç”¨æˆ–æœ¬èº«æ¸…æ™°ã€‚ä¾‹å¦‚ï¼Œå°æ–¼*ã€Œä½ çš„åå­—ã€*æª¢ç´¢(Retrieval)*ã€ŒBerasã€*å¦‚æœè„«é›¢è„ˆçµ¡è³‡è¨Š(Context)æä¾›ï¼Œå°èŠå¤©æ©Ÿå™¨äººä¾†èªªå¯èƒ½æœƒæœ‰å•é¡Œã€‚é æœŸæ½›åœ¨å•é¡Œä¸¦åœ¨æ‚¨çš„ LLM çµ„ä»¶ä¹‹é–“å‰µå»ºå”åŒ(Synergized)å¯ä»¥å¢åŠ è‰¯å¥½ RAG è¡Œç‚ºçš„å¯èƒ½æ€§ï¼Œæ‰€ä»¥è«‹ç•™æ„é€™äº›é™·é˜±å’Œæ©Ÿæœƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZEDEzpqmTYMv",
   "metadata": {
    "id": "ZEDEzpqmTYMv"
   },
   "source": [
    "### **æ­¥é©Ÿ 3ï¼š**Â å°‡å°è©±æª¢ç´¢(Retrieval)æ•´åˆåˆ°æˆ‘å€‘çš„éˆ(Chain)ä¸­\n",
    "\n",
    "\n",
    "ç¾åœ¨æˆ‘å€‘æœ‰äº†è¼‰å…¥çš„æª¢ç´¢å™¨çµ„ä»¶ä½œç‚ºéˆ(Chain)ï¼Œæˆ‘å€‘å¯ä»¥åƒä¹‹å‰ä¸€æ¨£å°‡å…¶æ•´åˆåˆ°æˆ‘å€‘ç¾æœ‰çš„èŠå¤©ç³»çµ±ä¸­ã€‚å…·é«”ä¾†èªªï¼Œæˆ‘å€‘å¯ä»¥å¾***å§‹çµ‚é–‹å•Ÿçš„ RAG åˆ¶å®š***é–‹å§‹ï¼Œå…¶ä¸­ï¼š\n",
    "\n",
    "-   **æª¢ç´¢å™¨é è¨­å§‹çµ‚åœ¨æª¢ç´¢(Retrieval)è„ˆçµ¡è³‡è¨Š(Context)** ã€‚\n",
    "\n",
    "-   **ç”Ÿæˆå™¨åœ¨æª¢ç´¢(Retrieval)çš„è„ˆçµ¡è³‡è¨Š(Context)ä¸Šè¡Œå‹•**ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64abe478-9bcb-4802-a26e-dc5a1756e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "########################################################################\n",
    "## Utility Runnables/Methods\n",
    "def RPrint(preface=\"\"):\n",
    "    \"\"\"Simple passthrough \"prints, then returns\" chain\"\"\"\n",
    "    def print_and_return(x, preface):\n",
    "        if preface: print(preface, end=\"\")\n",
    "        pprint(x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name:\n",
    "            out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "\n",
    "## Optional; Reorders longer documents to center of output text\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uue5UY3_TcvF",
   "metadata": {
    "id": "uue5UY3_TcvF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Based on the context provided, Beras lives in the Arctic. It seems like the Rocky Mountains are a fascinating place</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">for Beras to learn about, considering the vastly different climate from where they currently reside!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mBased on the context provided, Beras lives in the Arctic. It seems like the Rocky Mountains are a fascinating place\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mfor Beras to learn about, considering the vastly different climate from where they currently reside!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {question}\"\n",
    "    \"\\nAnswer the user conversationally. User is not aware of context.\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'question': (lambda x:x)\n",
    "    }\n",
    "    | context_prompt\n",
    "    # | RPrint()\n",
    "    | instruct_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"Where does Beras live?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FSIqTMuuTjIh",
   "metadata": {
    "id": "FSIqTMuuTjIh"
   },
   "source": [
    "\n",
    "\n",
    "èŠ±ä¸€é»æ™‚é–“å˜—è©¦æ›´å¤šinvokeä¸¦çœ‹çœ‹æ–°è¨­ç½®çš„è¡¨ç¾å¦‚ä½•ã€‚ç„¡è«–æ‚¨é¸æ“‡å“ªå€‹æ¨¡å‹ï¼Œä»¥ä¸‹å•é¡Œéƒ½æ‡‰è©²ä½œç‚ºæœ‰è¶£çš„èµ·é»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4jDJwrYpTmpd",
   "metadata": {
    "id": "4jDJwrYpTmpd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Hello there! The Rocky Mountains are a stunning range of mountains that span across North America. You can learn </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">more about them by doing some online research or watching documentaries if you're interested!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mHello there! The Rocky Mountains are a stunning range of mountains that span across North America. You can learn \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmore about them by doing some online research or watching documentaries if you're interested!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "-artagLfTpBy",
   "metadata": {
    "id": "-artagLfTpBy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Hello there! The Rocky Mountains are a stunning range of mountains that stretch across North America. To answer </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">your question about their location, they run from northern British Columbia in Canada all the way down to New </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Mexico in the United States. As for their proximity to California, they don't directly border the state. The </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">closest parts of the Rocky Mountains to California would be in Nevada or Idaho, which are still quite a distance </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">away. I hope that helps! Let's continue exploring more about the Rocky Mountains if you have any other questions.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mHello there! The Rocky Mountains are a stunning range of mountains that stretch across North America. To answer \u001b[0m\n",
       "\u001b[1;38;2;118;185;0myour question about their location, they run from northern British Columbia in Canada all the way down to New \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mMexico in the United States. As for their proximity to California, they don't directly border the state. The \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mclosest parts of the Rocky Mountains to California would be in Nevada or Idaho, which are still quite a distance \u001b[0m\n",
       "\u001b[1;38;2;118;185;0maway. I hope that helps! Let's continue exploring more about the Rocky Mountains if you have any other questions.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains? Are they close to California?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "GDgjdfdpTrV5",
   "metadata": {
    "id": "GDgjdfdpTrV5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Unfortunately, the context doesn't provide information on Beras' exact location or distance from the Rocky </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Mountains. I can tell you, though, that the Rocky Mountains are a beautiful and majestic range of mountains </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">stretching across North America. If you'd like, I can search for more information about their geographical location</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and specific details about their range.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mUnfortunately, the context doesn't provide information on Beras' exact location or distance from the Rocky \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mMountains. I can tell you, though, that the Rocky Mountains are a beautiful and majestic range of mountains \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mstretching across North America. If you'd like, I can search for more information about their geographical location\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand specific details about their range.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"How far away is Beras from the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8wp9-8CbT0L9",
   "metadata": {
    "id": "8wp9-8CbT0L9"
   },
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "æ‚¨å¯èƒ½æœƒæ³¨æ„åˆ°é€™å€‹å§‹çµ‚é–‹å•Ÿçš„æª¢ç´¢(Retrieval)ç¯€é»(Node)åœ¨è¿´åœˆä¸­æœ‰ä¸€äº›ä¸éŒ¯çš„æ•ˆèƒ½ï¼Œå› ç‚ºå¯¦éš›é¤µçµ¦ LLM çš„è„ˆçµ¡è³‡è¨Š(Context)ä¿æŒç›¸å°è¼ƒå°ã€‚é‡è¦çš„æ˜¯è¦å¯¦é©—å…§åµŒ(Embedding)å¤§å°ã€è„ˆçµ¡è³‡è¨Š(Context)é™åˆ¶å’Œæ¨¡å‹é¸é …ç­‰å› ç´ ï¼Œçœ‹çœ‹æ‚¨å¯ä»¥æœŸå¾…ä»€éº¼æ¨£çš„è¡Œç‚ºï¼Œä»¥åŠå“ªäº›åŠªåŠ›å€¼å¾—æ¡å–ä¾†æ”¹å–„æ•ˆèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OnpOybOhUCTf",
   "metadata": {
    "id": "OnpOybOhUCTf"
   },
   "source": [
    "### **æ­¥é©Ÿ 4ï¼š**Â è‡ªå‹•å°è©±å„²å­˜\n",
    "\n",
    "\n",
    "ç¾åœ¨æˆ‘å€‘çœ‹åˆ°æˆ‘å€‘çš„å‘é‡å­˜å„²åº«(Vector Store)è¨˜æ†¶é«”å–®å…ƒæ‡‰è©²å¦‚ä½•é‹ä½œï¼Œæˆ‘å€‘å¯ä»¥åŸ·è¡Œæœ€å¾Œä¸€å€‹æ•´åˆï¼Œå…è¨±æˆ‘å€‘çš„å°è©±å‘æˆ‘å€‘çš„å°è©±æ·»åŠ æ–°è³‡æ–™(Entries)ï¼šä¸€å€‹ç‚ºæˆ‘å€‘å‘¼å«Â `add_texts`Â æ–¹æ³•ä¾†æ›´æ–°å­˜å„²ç‹€æ…‹çš„å¯é‹è¡Œç‰©ä»¶(Runnable)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "FsK6-AtRVdcZ",
   "metadata": {
    "id": "FsK6-AtRVdcZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">While I'm sure the Rocky Mountains would provide a magnificent backdrop for enjoying ice cream, it's essential to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">remember that it's a vast mountain range spanning over </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> miles across North America. There are many activities </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">to do there, like hiking, camping, and sightseeing. However, if you find yourself near a local town or village, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">there might be a place to grab some ice cream and savor the flavors as you take in the breathtaking views! But </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Beras, let's focus on the incredible natural wonders the Rocky Mountains have to offer first!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mWhile I'm sure the Rocky Mountains would provide a magnificent backdrop for enjoying ice cream, it's essential to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mremember that it's a vast mountain range spanning over \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\u001b[1;36m000\u001b[0m\u001b[1;38;2;118;185;0m miles across North America. There are many activities \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mto do there, like hiking, camping, and sightseeing. However, if you find yourself near a local town or village, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthere might be a place to grab some ice cream and savor the flavors as you take in the breathtaking views! But \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mBeras, let's focus on the incredible natural wonders the Rocky Mountains have to offer first!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Well, Beras, based on our conversation, it seems your favorite food might just be ice cream! Remember, as much as </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">you're excited about enjoying ice cream amidst the stunning Rocky Mountains, don't forget to explore all the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">incredible natural wonders it has to offer first!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mWell, Beras, based on our conversation, it seems your favorite food might just be ice cream! Remember, as much as \u001b[0m\n",
       "\u001b[1;38;2;118;185;0myou're excited about enjoying ice cream amidst the stunning Rocky Mountains, don't forget to explore all the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mincredible natural wonders it has to offer first!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">I apologize for the misunderstanding, Beras. I inferred that ice cream was your favorite food because it came up in</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">our discussion about the Rocky Mountains. From what I can see now, I must have misunderstood. I'm glad you've </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">clarified that your true favorite is honey! I'll make sure to remember that for future reference.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mI apologize for the misunderstanding, Beras. I inferred that ice cream was your favorite food because it came up in\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mour discussion about the Rocky Mountains. From what I can see now, I must have misunderstood. I'm glad you've \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mclarified that your true favorite is honey! I'll make sure to remember that for future reference.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Absolutely, Beras! I do now. I'm sorry for the confusion earlier. Based on your clarification, I now understand </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">that your favorite food is honey. I'll keep that in mind for our future conversations.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAbsolutely, Beras! I do now. I'm sorry for the confusion earlier. Based on your clarification, I now understand \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthat your favorite food is honey. I'll keep that in mind for our future conversations.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "########################################################################\n",
    "## Reset knowledge base and define what it means to add more messages.\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([f\"User said {d.get('input')}\", f\"Agent said {d.get('output')}\"])\n",
    "    return d.get('output')\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {input}\"\n",
    "    \"\\nAnswer the user conversationally. Make sure the conversation flows naturally.\\n\"\n",
    "    \"[Agent]\"\n",
    ")\n",
    "\n",
    "\n",
    "conv_chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'input': (lambda x:x)\n",
    "    }\n",
    "    | RunnableAssign({'output' : chat_prompt | instruct_llm | StrOutputParser()})\n",
    "    | partial(save_memory_and_get_output, vstore=convstore)\n",
    ")\n",
    "\n",
    "pprint(conv_chain.invoke(\"I'm glad you agree! I can't wait to get some ice cream there! It's such a good food!\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Can you guess what my favorite food is?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Actually, my favorite is honey! Not sure where you got that idea?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"I see! Fair enough! Do you know my favorite food now?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KRMW6G7NVSWF",
   "metadata": {
    "id": "KRMW6G7NVSWF"
   },
   "source": [
    "\n",
    "èˆ‡æ›´è‡ªå‹•çš„å°‡è„ˆçµ¡è³‡è¨Š(Context)æ³¨å…¥LLM çš„å…¨æ–‡(full-text)æˆ–åŸºæ–¼è¦å‰‡(rule-based approaches)çš„æ–¹æ³•ä¸åŒï¼Œé€™ç¨®æ–¹æ³•ç¢ºä¿äº†ä¸€å®šç¨‹åº¦çš„æ•´åˆ(Aggregate)ï¼Œå¯ä»¥é˜²æ­¢è„ˆçµ¡è³‡è¨Š(Context)é•·åº¦å¤±æ§ã€‚å®ƒæœ¬èº«ä»ç„¶ä¸æ˜¯ä¸€å€‹è¬ç„¡ä¸€å¤±çš„ç­–ç•¥ï¼Œä½†å°æ–¼éçµæ§‹åŒ–å°è©±ä¾†èªªæ˜¯ä¸€å€‹é¡¯è‘—çš„æ”¹é€²ï¼ˆç”šè‡³ä¸éœ€è¦å¼·å¤§çš„æŒ‡ä»¤èª¿æ•´æ¨¡å‹ä¾†åŸ·è¡Œæ§½å¡«å……ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9TPkh3SaLbqh",
   "metadata": {
    "id": "9TPkh3SaLbqh"
   },
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬ä¸‰éƒ¨åˆ† [ç·´ç¿’]ï¼š**Â æ–‡ä»¶åˆ†å¡Šæª¢ç´¢(Retrieval)çš„ RAG\n",
    "\n",
    "\n",
    "è€ƒæ…®åˆ°æˆ‘å€‘ä¹‹å‰å°æ–‡ä»¶è¼‰å…¥çš„æ¢ç´¢ï¼Œè³‡æ–™åˆ†å¡Šå¯ä»¥è¢«å…§åµŒ(Embedding)å’Œæœå°‹çš„æƒ³æ³•å¯èƒ½ä¸¦ä¸ä»¤äººé©šè¨ã€‚è©±é›–å¦‚æ­¤ï¼Œé€™çµ•å°å€¼å¾—å›é¡§ï¼Œå› ç‚ºå°‡ RAG æ‡‰ç”¨æ–¼æ–‡ä»¶æ˜¯ä¸€æŠŠé›™åˆƒåŠï¼›å®ƒå¯èƒ½**çœ‹èµ·ä¾†**é–‹ç®±å³ç”¨é‹ä½œè‰¯å¥½ï¼Œä½†åœ¨ç‚ºçœŸæ­£å¯é çš„æ•ˆèƒ½æœ€ä½³åŒ–æ™‚éœ€è¦ä¸€äº›é¡å¤–çš„æ³¨æ„ã€‚å®ƒä¹Ÿæä¾›äº†ä¸€å€‹çµ•ä½³çš„æ©Ÿæœƒä¾†å›é¡§ä¸€äº›åŸºæœ¬çš„ LCEL æŠ€èƒ½ï¼Œæ‰€ä»¥è®“æˆ‘å€‘çœ‹çœ‹æˆ‘å€‘èƒ½åšä»€éº¼ï¼\n",
    "<br>\n",
    "\n",
    "### **ç·´ç¿’ï¼š**\n",
    "\n",
    "\n",
    "åœ¨å‰é¢çš„ç¯„ä¾‹ä¸­ï¼Œæ‚¨å¯èƒ½è¨˜å¾—æˆ‘å€‘ä½¿ç”¨Â [`ArxivLoader`](https://python.langchain.com/docs/integrations/document_loaders/arxiv)Â çš„å¹«åŠ©æ‹‰å…¥äº†ä¸€äº›ç›¸å°è¼ƒå°çš„è«–æ–‡ï¼Œä½¿ç”¨ä»¥ä¸‹èªæ³•ï¼š\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "docs = [\n",
    "    ArxivLoader(query=\"2205.00445\").load(),  ## MRKL\n",
    "    ArxivLoader(query=\"2210.03629\").load(),  ## ReAct\n",
    "]\n",
    "```\n",
    "\n",
    "è€ƒæ…®åˆ°æ‚¨åˆ°ç›®å‰ç‚ºæ­¢å­¸åˆ°çš„ä¸€åˆ‡ï¼Œé¸æ“‡æ‚¨æƒ³è¦ä½¿ç”¨çš„è«–æ–‡é¸æ“‡ï¼Œä¸¦é–‹ç™¼ä¸€å€‹å¯ä»¥è«‡è«–å®ƒå€‘çš„èŠå¤©æ©Ÿå™¨äººï¼\n",
    "\n",
    "é›–ç„¶é€™æ˜¯ä¸€å€‹ç›¸ç•¶å¤§çš„ä»»å‹™ï¼Œä½†ä¸‹é¢å°‡æä¾›***å¤§éƒ¨åˆ†***æµç¨‹çš„æ¼”ç·´ã€‚åœ¨æ¼”ç·´çµæŸæ™‚ï¼Œå°‡æä¾›è¨±å¤šå¿…è¦çš„æ‹¼åœ–ç‰‡æ®µï¼Œæ‚¨çš„çœŸæ­£ä»»å‹™å°‡æ˜¯å°‡å®ƒå€‘æ•´åˆåœ¨ä¸€èµ·ç”¨æ–¼æœ€çµ‚çš„Â `retrieval_chain`ã€‚å®Œæˆå¾Œï¼Œæº–å‚™åœ¨æœ€å¾Œä¸€å€‹ notebook ä¸­é‡æ–°æ•´åˆéˆ(Chain)ï¼ˆæˆ–æ‚¨é¸æ“‡çš„é¢¨æ ¼ï¼‰ä½œç‚ºè©•é‡(Assessment)ç·´ç¿’çš„ä¸€éƒ¨åˆ†ï¼\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jSjfCtiQnj9e",
   "metadata": {
    "id": "jSjfCtiQnj9e"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **ä»»å‹™ 1**ï¼šè¼‰å…¥å’Œåˆ†å¡Š(Chunking)æ‚¨çš„æ–‡ä»¶\n",
    "\n",
    "\n",
    "ä»¥ä¸‹ç¨‹å¼ç¢¼å€å¡Šç‚ºæ‚¨æä¾›äº†ä¸€äº›é è¨­è«–æ–‡ï¼Œä¾›æ‚¨çš„ RAG éˆ(Chain)è¼‰å…¥ã€‚è«‹éš¨æ„é¸æ“‡æ›´å¤šè«–æ–‡ï¼Œä½†è«‹æ³¨æ„è¼ƒé•·çš„æ–‡ä»¶å°‡éœ€è¦æ›´é•·çš„è™•ç†æ™‚é–“ã€‚åŒ…å«äº†ä¸€äº›ç°¡åŒ–å‡è¨­å’Œé¡å¤–çš„è™•ç†æ­¥é©Ÿï¼Œä»¥å¹«åŠ©æ‚¨æ”¹å–„æœ€å–®ç´”çš„(naive) RAG æ•ˆèƒ½ï¼š\n",
    "\n",
    "-   å¦‚æœå­˜åœ¨ã€ŒReferencesã€éƒ¨åˆ†ï¼Œæ–‡ä»¶æœƒåœ¨æ­¤ä¹‹å‰è¢«æˆªæ–·ã€‚é€™å°‡é˜²æ­¢æˆ‘å€‘çš„ç³»çµ±è€ƒæ…®å¼•ç”¨å’Œé™„éŒ„éƒ¨åˆ†ï¼Œé€™äº›éƒ¨åˆ†å¾€å¾€å¾ˆé•·ä¸”ä»¤äººåˆ†å¿ƒã€‚\n",
    "\n",
    "-   æ’å…¥ä¸€å€‹åˆ—å‡ºå¯ç”¨æ–‡ä»¶çš„åˆ†å¡Šï¼Œä»¥åœ¨å–®ä¸€åˆ†å¡Šä¸­æä¾›æ‰€æœ‰å¯ç”¨æ–‡ä»¶çš„é«˜éšè¦–åœ–ã€‚å¦‚æœæ‚¨çš„ç®¡ç·š(Pipeline)åœ¨æ¯æ¬¡æª¢ç´¢(Retrieval)æ™‚ä¸æä¾›ä¸­ä»‹è³‡æ–™(Metadata)ï¼Œé€™æ˜¯ä¸€å€‹æœ‰ç”¨çš„çµ„ä»¶ï¼Œç”šè‡³å¯ä»¥åœ¨é©ç•¶æ™‚åˆ—åœ¨æ›´é«˜å„ªå…ˆç´šç‰‡æ®µçš„æ¸…å–®ä¸­ã€‚\n",
    "\n",
    "-   æ­¤å¤–ï¼Œä¸­ä»‹è³‡æ–™(Metadata)è³‡æ–™(Entries)ä¹Ÿè¢«æ’å…¥ä»¥æä¾›ä¸€èˆ¬è³‡è¨Šã€‚ç†æƒ³æƒ…æ³ä¸‹ï¼Œé‚„æœƒæœ‰ä¸€äº›ç¶œåˆçµæœ(Synthesis)åˆ†å¡Šå°‡ä¸­ä»‹è³‡æ–™(Metadata)åˆä½µåˆ°æœ‰è¶£çš„è·¨æ–‡ä»¶åˆ†å¡Šä¸­ã€‚\n",
    "\n",
    "**æ³¨æ„ï¼š**Â ***ç‚ºäº†è©•é‡(Assessment)çš„ç›®çš„ï¼Œè«‹è‡³å°‘åŒ…å«ä¸€ç¯‡ä¸åˆ°ä¸€å€‹æœˆçš„è«–æ–‡ï¼***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "S-3FBdT_lhVT",
   "metadata": {
    "id": "S-3FBdT_lhVT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Documents\n",
      "Chunking Documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Available Documents:</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Attention Is All You Need</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">sources and discrete reasoning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Mistral 7B</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAvailable Documents:\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Attention Is All You Need\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msources and discrete reasoning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Mistral 7B\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0\n",
      " - # Chunks: 35\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-08-02'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Attention Is All You Need'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Kaiser, Illia Polosukhin'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">constituency parsing both with large and limited training data.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-08-02'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Attention Is All You Need'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz \u001b[0m\n",
       "\u001b[32mKaiser, Illia Polosukhin'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural \u001b[0m\n",
       "\u001b[32mnetworks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder \u001b[0m\n",
       "\u001b[32mthrough an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on \u001b[0m\n",
       "\u001b[32mattention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation\u001b[0m\n",
       "\u001b[32mtasks show these models to be\\nsuperior in quality while being more parallelizable and requiring \u001b[0m\n",
       "\u001b[32msignificantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation \u001b[0m\n",
       "\u001b[32mtask, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 \u001b[0m\n",
       "\u001b[32mEnglish-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 \u001b[0m\n",
       "\u001b[32mafter training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the \u001b[0m\n",
       "\u001b[32mliterature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish \u001b[0m\n",
       "\u001b[32mconstituency parsing both with large and limited training data.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1\n",
      " - # Chunks: 45\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2019-05-24'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'We introduce a new language representation model called BERT, which stands\\nfor Bidirectional </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Encoder Representations from Transformers. Unlike recent\\nlanguage representation models, BERT is designed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-train deep\\nbidirectional representations from unlabeled text by jointly conditioning on\\nboth left and right </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context in all layers. As a result, the pre-trained BERT\\nmodel can be fine-tuned with just one additional output </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layer to create\\nstate-of-the-art models for a wide range of tasks, such as question answering\\nand language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inference, without substantial task-specific architecture\\nmodifications.\\n  BERT is conceptually simple and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">empirically powerful. It obtains new\\nstate-of-the-art results on eleven natural language processing tasks, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including\\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\\naccuracy to 86.7% (4.6% </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">absolute improvement), SQuAD v1.1 question answering\\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">v2.0 Test F1 to 83.1\\n(5.1 point absolute improvement).'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2019-05-24'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'We introduce a new language representation model called BERT, which stands\\nfor Bidirectional \u001b[0m\n",
       "\u001b[32mEncoder Representations from Transformers. Unlike recent\\nlanguage representation models, BERT is designed to \u001b[0m\n",
       "\u001b[32mpre-train deep\\nbidirectional representations from unlabeled text by jointly conditioning on\\nboth left and right \u001b[0m\n",
       "\u001b[32mcontext in all layers. As a result, the pre-trained BERT\\nmodel can be fine-tuned with just one additional output \u001b[0m\n",
       "\u001b[32mlayer to create\\nstate-of-the-art models for a wide range of tasks, such as question answering\\nand language \u001b[0m\n",
       "\u001b[32minference, without substantial task-specific architecture\\nmodifications.\\n  BERT is conceptually simple and \u001b[0m\n",
       "\u001b[32mempirically powerful. It obtains new\\nstate-of-the-art results on eleven natural language processing tasks, \u001b[0m\n",
       "\u001b[32mincluding\\npushing the GLUE score to 80.5% \u001b[0m\u001b[32m(\u001b[0m\u001b[32m7.7% point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, MultiNLI\\naccuracy to 86.7% \u001b[0m\u001b[32m(\u001b[0m\u001b[32m4.6% \u001b[0m\n",
       "\u001b[32mabsolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, SQuAD v1.1 question answering\\nTest F1 to 93.2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1.5 point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and SQuAD \u001b[0m\n",
       "\u001b[32mv2.0 Test F1 to 83.1\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m5.1 point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 2\n",
      " - # Chunks: 46\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-04-12'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, Douwe Kiela'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Large pre-trained language models have been shown to store factual knowledge\\nin their parameters, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and achieve state-of-the-art results when fine-tuned on\\ndownstream NLP tasks. However, their ability to access and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">precisely manipulate\\nknowledge is still limited, and hence on knowledge-intensive tasks, their\\nperformance lags </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">behind task-specific architectures. Additionally, providing\\nprovenance for their decisions and updating their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world knowledge remain open\\nresearch problems. Pre-trained models with a differentiable access mechanism </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to\\nexplicit non-parametric memory can overcome this issue, but have so far been\\nonly investigated for extractive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">downstream tasks. We explore a general-purpose\\nfine-tuning recipe for retrieval-augmented generation (RAG) -- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models which\\ncombine pre-trained parametric and non-parametric memory for language\\ngeneration. We introduce RAG </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models where the parametric memory is a\\npre-trained seq2seq model and the non-parametric memory is a dense vector </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">index\\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\\nformulations, one which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conditions on the same retrieved passages across the\\nwhole generated sequence, the other can use different </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">passages per token. We\\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\\ntasks and set</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the state-of-the-art on three open domain QA tasks, outperforming\\nparametric seq2seq models and task-specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieve-and-extract architectures.\\nFor language generation tasks, we find that RAG models generate more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific,\\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\\nbaseline.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2021-04-12'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, \u001b[0m\n",
       "\u001b[32mHeinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, Douwe Kiela'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Large pre-trained language models have been shown to store factual knowledge\\nin their parameters, \u001b[0m\n",
       "\u001b[32mand achieve state-of-the-art results when fine-tuned on\\ndownstream NLP tasks. However, their ability to access and\u001b[0m\n",
       "\u001b[32mprecisely manipulate\\nknowledge is still limited, and hence on knowledge-intensive tasks, their\\nperformance lags \u001b[0m\n",
       "\u001b[32mbehind task-specific architectures. Additionally, providing\\nprovenance for their decisions and updating their \u001b[0m\n",
       "\u001b[32mworld knowledge remain open\\nresearch problems. Pre-trained models with a differentiable access mechanism \u001b[0m\n",
       "\u001b[32mto\\nexplicit non-parametric memory can overcome this issue, but have so far been\\nonly investigated for extractive \u001b[0m\n",
       "\u001b[32mdownstream tasks. We explore a general-purpose\\nfine-tuning recipe for retrieval-augmented generation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRAG\u001b[0m\u001b[32m)\u001b[0m\u001b[32m -- \u001b[0m\n",
       "\u001b[32mmodels which\\ncombine pre-trained parametric and non-parametric memory for language\\ngeneration. We introduce RAG \u001b[0m\n",
       "\u001b[32mmodels where the parametric memory is a\\npre-trained seq2seq model and the non-parametric memory is a dense vector \u001b[0m\n",
       "\u001b[32mindex\\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\\nformulations, one which \u001b[0m\n",
       "\u001b[32mconditions on the same retrieved passages across the\\nwhole generated sequence, the other can use different \u001b[0m\n",
       "\u001b[32mpassages per token. We\\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\\ntasks and set\u001b[0m\n",
       "\u001b[32mthe state-of-the-art on three open domain QA tasks, outperforming\\nparametric seq2seq models and task-specific \u001b[0m\n",
       "\u001b[32mretrieve-and-extract architectures.\\nFor language generation tasks, we find that RAG models generate more \u001b[0m\n",
       "\u001b[32mspecific,\\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\\nbaseline.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 3\n",
      " - # Chunks: 40\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2022-05-01'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge sources and discrete reasoning'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Amnon Shashua, Moshe Tenenholtz'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Huge language models (LMs) have ushered in a new era for AI, serving as a\\ngateway to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural-language-based knowledge tasks. Although an essential\\nelement of modern AI, LMs are also inherently </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limited in a number of ways. We\\ndiscuss these limitations and how they can be avoided by adopting a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systems\\napproach. Conceptualizing the challenge as one that involves knowledge and\\nreasoning in addition to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">linguistic processing, we define a flexible\\narchitecture with multiple neural models, complemented by discrete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge\\nand reasoning modules. We describe this neuro-symbolic architecture, dubbed the\\nModular Reasoning, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge and Language (MRKL, pronounced \"miracle\") system,\\nsome of the technical challenges in implementing it, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and Jurassic-X, AI21 Labs\\'\\nMRKL system implementation.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2022-05-01'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external \u001b[0m\n",
       "\u001b[32mknowledge sources and discrete reasoning'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit\u001b[0m\n",
       "\u001b[32mBata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, \u001b[0m\n",
       "\u001b[32mAmnon Shashua, Moshe Tenenholtz'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Huge language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have ushered in a new era for AI, serving as a\\ngateway to \u001b[0m\n",
       "\u001b[32mnatural-language-based knowledge tasks. Although an essential\\nelement of modern AI, LMs are also inherently \u001b[0m\n",
       "\u001b[32mlimited in a number of ways. We\\ndiscuss these limitations and how they can be avoided by adopting a \u001b[0m\n",
       "\u001b[32msystems\\napproach. Conceptualizing the challenge as one that involves knowledge and\\nreasoning in addition to \u001b[0m\n",
       "\u001b[32mlinguistic processing, we define a flexible\\narchitecture with multiple neural models, complemented by discrete \u001b[0m\n",
       "\u001b[32mknowledge\\nand reasoning modules. We describe this neuro-symbolic architecture, dubbed the\\nModular Reasoning, \u001b[0m\n",
       "\u001b[32mKnowledge and Language \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMRKL, pronounced \"miracle\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m system,\\nsome of the technical challenges in implementing it, \u001b[0m\n",
       "\u001b[32mand Jurassic-X, AI21 Labs\\'\\nMRKL system implementation.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 4\n",
      " - # Chunks: 21\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-10-10'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Mistral 7B'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, LÃ©lio Renard Lavaud, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, TimothÃ©e Lacroix, William El Sayed'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered\\nfor superior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance and efficiency. Mistral 7B outperforms Llama 2 13B\\nacross all evaluated benchmarks, and Llama 1 34B in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning, mathematics, and\\ncode generation. Our model leverages grouped-query attention (GQA) for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">faster\\ninference, coupled with sliding window attention (SWA) to effectively handle\\nsequences of arbitrary length</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with a reduced inference cost. We also provide a\\nmodel fine-tuned to follow instructions, Mistral 7B -- Instruct, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that surpasses\\nthe Llama 2 13B -- Chat model both on human and automated benchmarks. Our\\nmodels are released </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">under the Apache 2.0 license.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-10-10'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Mistral 7B'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, \u001b[0m\n",
       "\u001b[32mDiego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, LÃ©lio Renard Lavaud, \u001b[0m\n",
       "\u001b[32mMarie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, TimothÃ©e Lacroix, William El Sayed'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered\\nfor superior \u001b[0m\n",
       "\u001b[32mperformance and efficiency. Mistral 7B outperforms Llama 2 13B\\nacross all evaluated benchmarks, and Llama 1 34B in\u001b[0m\n",
       "\u001b[32mreasoning, mathematics, and\\ncode generation. Our model leverages grouped-query attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGQA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for \u001b[0m\n",
       "\u001b[32mfaster\\ninference, coupled with sliding window attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSWA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to effectively handle\\nsequences of arbitrary length\u001b[0m\n",
       "\u001b[32mwith a reduced inference cost. We also provide a\\nmodel fine-tuned to follow instructions, Mistral 7B -- Instruct, \u001b[0m\n",
       "\u001b[32mthat surpasses\\nthe Llama 2 13B -- Chat model both on human and automated benchmarks. Our\\nmodels are released \u001b[0m\n",
       "\u001b[32munder the Apache 2.0 license.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 5\n",
      " - # Chunks: 44\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-12-24'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Evaluating large language model (LLM) based chat assistants is challenging\\ndue to their broad </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities and the inadequacy of existing benchmarks in\\nmeasuring human preferences. To address this, we explore</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using strong LLMs as\\njudges to evaluate these models on more open-ended questions. We examine the\\nusage and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limitations of LLM-as-a-judge, including position, verbosity, and\\nself-enhancement biases, as well as limited </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning ability, and propose\\nsolutions to mitigate some of them. We then verify the agreement between </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM\\njudges and human preferences by introducing two benchmarks: MT-bench, a\\nmulti-turn question set; and Chatbot </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Arena, a crowdsourced battle platform. Our\\nresults reveal that strong LLM judges like GPT-4 can match both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">controlled and\\ncrowdsourced human preferences well, achieving over 80% agreement, the same\\nlevel of agreement </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between humans. Hence, LLM-as-a-judge is a scalable and\\nexplainable way to approximate human preferences, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are otherwise very\\nexpensive to obtain. Additionally, we show our benchmark and traditional\\nbenchmarks complement</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each other by evaluating several variants of LLaMA and\\nVicuna. The MT-bench questions, 3K expert votes, and 30K </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations with\\nhuman preferences are publicly available </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at\\nhttps://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-12-24'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, \u001b[0m\n",
       "\u001b[32mZhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Evaluating large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m based chat assistants is challenging\\ndue to their broad \u001b[0m\n",
       "\u001b[32mcapabilities and the inadequacy of existing benchmarks in\\nmeasuring human preferences. To address this, we explore\u001b[0m\n",
       "\u001b[32musing strong LLMs as\\njudges to evaluate these models on more open-ended questions. We examine the\\nusage and \u001b[0m\n",
       "\u001b[32mlimitations of LLM-as-a-judge, including position, verbosity, and\\nself-enhancement biases, as well as limited \u001b[0m\n",
       "\u001b[32mreasoning ability, and propose\\nsolutions to mitigate some of them. We then verify the agreement between \u001b[0m\n",
       "\u001b[32mLLM\\njudges and human preferences by introducing two benchmarks: MT-bench, a\\nmulti-turn question set; and Chatbot \u001b[0m\n",
       "\u001b[32mArena, a crowdsourced battle platform. Our\\nresults reveal that strong LLM judges like GPT-4 can match both \u001b[0m\n",
       "\u001b[32mcontrolled and\\ncrowdsourced human preferences well, achieving over 80% agreement, the same\\nlevel of agreement \u001b[0m\n",
       "\u001b[32mbetween humans. Hence, LLM-as-a-judge is a scalable and\\nexplainable way to approximate human preferences, which \u001b[0m\n",
       "\u001b[32mare otherwise very\\nexpensive to obtain. Additionally, we show our benchmark and traditional\\nbenchmarks complement\u001b[0m\n",
       "\u001b[32meach other by evaluating several variants of LLaMA and\\nVicuna. The MT-bench questions, 3K expert votes, and 30K \u001b[0m\n",
       "\u001b[32mconversations with\\nhuman preferences are publicly available \u001b[0m\n",
       "\u001b[32mat\\nhttps://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \"],\n",
    ")\n",
    "\n",
    "## TODO: Please pick some papers and add them to the list as you'd like\n",
    "## NOTE: To re-use for the final assessment, make sure at least one paper is < 1 month old\n",
    "print(\"Loading Documents\")\n",
    "docs = [\n",
    "    ArxivLoader(query=\"1706.03762\").load(),  ## Attention Is All You Need Paper\n",
    "    ArxivLoader(query=\"1810.04805\").load(),  ## BERT Paper\n",
    "    ArxivLoader(query=\"2005.11401\").load(),  ## RAG Paper\n",
    "    ArxivLoader(query=\"2205.00445\").load(),  ## MRKL Paper\n",
    "    ArxivLoader(query=\"2310.06825\").load(),  ## Mistral Paper\n",
    "    ArxivLoader(query=\"2306.05685\").load(),  ## LLM-as-a-Judge\n",
    "    ## Some longer papers\n",
    "    # ArxivLoader(query=\"2210.03629\").load(),  ## ReAct Paper\n",
    "    # ArxivLoader(query=\"2112.10752\").load(),  ## Latent Stable Diffusion Paper\n",
    "    # ArxivLoader(query=\"2103.00020\").load(),  ## CLIP Paper\n",
    "    ## TODO: Feel free to add more\n",
    "]\n",
    "\n",
    "## Cut the paper short if references is included.\n",
    "## This is a standard string in papers.\n",
    "for doc in docs:\n",
    "    content = json.dumps(doc[0].page_content)\n",
    "    if \"References\" in content:\n",
    "        doc[0].page_content = content[:content.index(\"References\")]\n",
    "\n",
    "## Split the documents and also filter out stubs (overly short chunks)\n",
    "print(\"Chunking Documents\")\n",
    "docs_chunks = [text_splitter.split_documents(doc) for doc in docs]\n",
    "docs_chunks = [[c for c in dchunks if len(c.page_content) > 200] for dchunks in docs_chunks]\n",
    "\n",
    "## Make some custom Chunks to give big-picture details\n",
    "doc_string = \"Available Documents:\"\n",
    "doc_metadata = []\n",
    "for chunks in docs_chunks:\n",
    "    metadata = getattr(chunks[0], 'metadata', {})\n",
    "    doc_string += \"\\n - \" + metadata.get('Title')\n",
    "    doc_metadata += [str(metadata)]\n",
    "\n",
    "extra_chunks = [doc_string] + doc_metadata\n",
    "\n",
    "## Printing out some summary information for reference\n",
    "pprint(doc_string, '\\n')\n",
    "for i, chunks in enumerate(docs_chunks):\n",
    "    print(f\"Document {i}\")\n",
    "    print(f\" - # Chunks: {len(chunks)}\")\n",
    "    print(f\" - Metadata: \")\n",
    "    pprint(chunks[0].metadata)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4pWU_OOnnrsT",
   "metadata": {
    "id": "4pWU_OOnnrsT"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **ä»»å‹™ 2**ï¼šå»ºæ§‹æ‚¨çš„æ–‡ä»¶å‘é‡å­˜å„²åº«(Vector Store)\n",
    "\n",
    "\n",
    "ç¾åœ¨æˆ‘å€‘æœ‰äº†æ‰€æœ‰çµ„ä»¶ï¼Œæˆ‘å€‘å¯ä»¥ç¹¼çºŒå‰µå»ºåœç¹å®ƒå€‘çš„ç´¢å¼•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lwwmr3aptwCg",
   "metadata": {
    "id": "lwwmr3aptwCg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Vector Stores\n",
      "CPU times: user 587 ms, sys: 53.1 ms, total: 640 ms\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Constructing Vector Stores\")\n",
    "vecstores = [FAISS.from_texts(extra_chunks, embedder)]\n",
    "vecstores += [FAISS.from_documents(doc_chunks, embedder) for doc_chunks in docs_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j39JwCKubto0",
   "metadata": {
    "id": "j39JwCKubto0"
   },
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "å¾é‚£è£¡ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å¯¦ç”¨å·¥å…·å°‡æˆ‘å€‘çš„ç´¢å¼•åˆä½µç‚ºå–®ä¸€ç´¢å¼•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "Q7us66iPVc70",
   "metadata": {
    "id": "Q7us66iPVc70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed aggregate docstore with 238 chunks\n"
     ]
    }
   ],
   "source": [
    "from faiss import IndexFlatL2\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "embed_dims = len(embedder.embed_query(\"test\"))\n",
    "def default_FAISS():\n",
    "    '''Useful utility for making an empty FAISS vectorstore'''\n",
    "    return FAISS(\n",
    "        embedding_function=embedder,\n",
    "        index=IndexFlatL2(embed_dims),\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "        normalize_L2=False\n",
    "    )\n",
    "\n",
    "def aggregate_vstores(vectorstores):\n",
    "    ## Initialize an empty FAISS Index and merge others into it\n",
    "    ## We'll use default_faiss for simplicity, though it's tied to your embedder by reference\n",
    "    agg_vstore = default_FAISS()\n",
    "    for vstore in vectorstores:\n",
    "        agg_vstore.merge_from(vstore)\n",
    "    return agg_vstore\n",
    "\n",
    "## Unintuitive optimization; merge_from seems to optimize constituent vector stores away\n",
    "docstore = aggregate_vstores(vecstores)\n",
    "\n",
    "print(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VU_VEx2mqJUK",
   "metadata": {
    "id": "VU_VEx2mqJUK"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **ä»»å‹™ 3ï¼š[ç·´ç¿’]**Â å¯¦ä½œæ‚¨çš„ RAG éˆ(Chain)\n",
    "\n",
    "\n",
    "æœ€å¾Œï¼Œæ‰€æœ‰æ‹¼åœ–ç‰‡æ®µéƒ½å·²å°±ä½ä¾†å¯¦ä½œ RAG ç®¡ç·š(Pipeline)ï¼ä½œç‚ºå›é¡§ï¼Œæˆ‘å€‘ç¾åœ¨æœ‰ï¼š\n",
    "\n",
    "-   ä¸€ç¨®ç‚ºå°è©±è¨˜æ†¶(conversation memory)å¾é ­å»ºæ§‹å‘é‡å­˜å„²åº«(Vector Store)çš„æ–¹æ³•ï¼ˆä»¥åŠä½¿ç”¨Â `default_FAISS()`Â åˆå§‹åŒ–ç©ºå‘é‡å­˜å„²åº«(Vector Store)çš„æ–¹æ³•ï¼‰\n",
    "\n",
    "-   ä¸€å€‹é è¼‰äº†ä¾†è‡ªæˆ‘å€‘Â `ArxivLoader`Â å¯¦ç”¨å·¥å…·çš„æœ‰ç”¨æ–‡ä»¶è³‡è¨Šçš„å‘é‡å­˜å„²åº«(Vector Store)ï¼ˆå„²å­˜åœ¨Â `docstore`Â ä¸­ï¼‰ã€‚\n",
    "\n",
    "åœ¨å¹¾å€‹é¡å¤–å¯¦ç”¨å·¥å…·çš„å¹«åŠ©ä¸‹ï¼Œæ‚¨çµ‚æ–¼æº–å‚™å¥½æ•´åˆæ‚¨çš„éˆ(Chain)äº†ï¼æä¾›äº†ä¸€äº›é¡å¤–çš„ä¾¿åˆ©å¯¦ç”¨å·¥å…·ï¼ˆ`doc2str`Â å’Œç¾åœ¨å¸¸è¦‹(popular)çš„Â `RPrint`ï¼‰ï¼Œä½†ä½¿ç”¨æ˜¯å¯é¸çš„ã€‚æ­¤å¤–ï¼Œé‚„å®šç¾©äº†ä¸€äº›èµ·å§‹æç¤º(Prompt)å’Œçµæ§‹ã€‚\n",
    "\n",
    "> **è€ƒæ…®åˆ°æ‰€æœ‰é€™äº›ï¼š**Â è«‹å¯¦ä½œÂ `retrieval_chain`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "-RXSrb1GcNff",
   "metadata": {
    "id": "-RXSrb1GcNff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Tell me about RAG!'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'history'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'context'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] . We refer to this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decoding procedure as \\\\u201cThorough Decoding.\\\\u201d For longer\\\\noutput sequences, |Y | can become large, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requiring many forward passes. For more ef\\\\ufb01cient decoding,\\\\nwe can make a further approximation that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">p\\\\u03b8(y|x, zi) \\\\u22480 where y was not generated during beam\\\\nsearch from x, zi. This avoids the need to run </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">additional forward passes once the candidate set Y has\\\\nbeen generated. We refer to this decoding procedure as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\u201cFast Decoding.\\\\u201d\\\\n3\\\\nExperiments\\\\nWe experiment with RAG in a wide range of knowledge-intensive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks. For all experiments, we use\\\\na single Wikipedia dump for our non-parametric knowledge source. Following Lee</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">et al. [31] and\\\\nKarpukhin et al. [26], we use the December 2018 dump. Each Wikipedia article is split into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">disjoint\\\\n100-word chunks, to make a total of 21M documents\\n[Quote from Retrieval-Augmented Generation for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge-Intensive NLP Tasks] . Since RAG can be\\\\nemployed as a language model, similar concerns as for GPT-2 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">[50] are valid here, although arguably\\\\nto a lesser extent, including that it might be used to generate abuse, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">faked or misleading content in\\\\nthe news or on social media; to impersonate others; or to automate the production </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of spam/phishing\\\\ncontent [54]. Advanced language models may also lead to the automation of various jobs in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\\\ncoming decades [16]. In order to mitigate these risks, AI systems could be employed to \\\\ufb01ght </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">against\\\\nmisleading content and automated spam/phishing.\\\\nAcknowledgments\\\\nThe authors would like to thank the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reviewers for their thoughtful and constructive feedback on this\\\\npaper, as well as HuggingFace for their help in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">open-sourcing code to run RAG models. The authors\\\\nwould also like to thank Kyunghyun Cho and Sewon Min for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">productive discussions and advice. EP\\\\nthanks supports from the NSF Graduate Research Fellowship. PL is supported </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by the FAIR PhD\\\\nprogram.\\\\n\\n[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">.\\\\nRAG-Token\\\\nThe RAG-Token model can be seen as a standard, autoregressive seq2seq genera-\\\\ntor with transition</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probability: p\\\\u2032\\\\n\\\\u03b8(yi|x, y1:i\\\\u22121) = P\\\\nz\\\\u2208top-k(p(\\\\u00b7|x)) p\\\\u03b7(zi|x)p\\\\u03b8(yi|x, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">zi, y1:i\\\\u22121) To\\\\ndecode, we can plug p\\\\u2032\\\\n\\\\u03b8(yi|x, y1:i\\\\u22121) into a standard beam </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decoder.\\\\nRAG-Sequence\\\\nFor RAG-Sequence, the likelihood p(y|x) does not break into a conventional per-\\\\ntoken </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for\\\\neach document z, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scoring each hypothesis using p\\\\u03b8(yi|x, z, y1:i\\\\u22121). This yields a set of hypotheses\\\\nY , some of which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">may not have appeared in the beams of all documents. To estimate the probability\\\\nof an hypothesis y we run an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">additional forward pass for each document z for which y does not\\\\nappear in the beam, multiply generator </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probability with p\\\\u03b7(z|x) and then sum the probabilities across\\\\nbeams for the marginals\\n[Quote from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] . In one approach, RAG-Sequence, the model uses </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the same document\\\\nto predict each target token. The second approach, RAG-Token, can predict each target token </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">based\\\\non a different document. In the following, we formally introduce both models and then describe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\\\np\\\\u03b7 and p\\\\u03b8 components, as well as the training and decoding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">procedure.\\\\n2.1\\\\nModels\\\\nRAG-Sequence Model\\\\nThe RAG-Sequence model uses the same retrieved document to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generate\\\\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that\\\\nis marginalized to get the seq2seq probability p(y|x) via a top-K approximation\\n'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Tell me about RAG!'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'history'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m''\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'context'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . We refer to this \u001b[0m\n",
       "\u001b[32mdecoding procedure as \\\\u201cThorough Decoding.\\\\u201d For longer\\\\noutput sequences, |Y | can become large, \u001b[0m\n",
       "\u001b[32mrequiring many forward passes. For more ef\\\\ufb01cient decoding,\\\\nwe can make a further approximation that \u001b[0m\n",
       "\u001b[32mp\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x, zi\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\u22480 where y was not generated during beam\\\\nsearch from x, zi. This avoids the need to run \u001b[0m\n",
       "\u001b[32madditional forward passes once the candidate set Y has\\\\nbeen generated. We refer to this decoding procedure as \u001b[0m\n",
       "\u001b[32m\\\\u201cFast Decoding.\\\\u201d\\\\n3\\\\nExperiments\\\\nWe experiment with RAG in a wide range of knowledge-intensive \u001b[0m\n",
       "\u001b[32mtasks. For all experiments, we use\\\\na single Wikipedia dump for our non-parametric knowledge source. Following Lee\u001b[0m\n",
       "\u001b[32met al. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m31\u001b[0m\u001b[32m]\u001b[0m\u001b[32m and\\\\nKarpukhin et al. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m26\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, we use the December 2018 dump. Each Wikipedia article is split into \u001b[0m\n",
       "\u001b[32mdisjoint\\\\n100-word chunks, to make a total of 21M documents\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Retrieval-Augmented Generation for \u001b[0m\n",
       "\u001b[32mKnowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . Since RAG can be\\\\nemployed as a language model, similar concerns as for GPT-2 \u001b[0m\n",
       "\u001b[32m[\u001b[0m\u001b[32m50\u001b[0m\u001b[32m]\u001b[0m\u001b[32m are valid here, although arguably\\\\nto a lesser extent, including that it might be used to generate abuse, \u001b[0m\n",
       "\u001b[32mfaked or misleading content in\\\\nthe news or on social media; to impersonate others; or to automate the production \u001b[0m\n",
       "\u001b[32mof spam/phishing\\\\ncontent \u001b[0m\u001b[32m[\u001b[0m\u001b[32m54\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Advanced language models may also lead to the automation of various jobs in \u001b[0m\n",
       "\u001b[32mthe\\\\ncoming decades \u001b[0m\u001b[32m[\u001b[0m\u001b[32m16\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. In order to mitigate these risks, AI systems could be employed to \\\\ufb01ght \u001b[0m\n",
       "\u001b[32magainst\\\\nmisleading content and automated spam/phishing.\\\\nAcknowledgments\\\\nThe authors would like to thank the \u001b[0m\n",
       "\u001b[32mreviewers for their thoughtful and constructive feedback on this\\\\npaper, as well as HuggingFace for their help in \u001b[0m\n",
       "\u001b[32mopen-sourcing code to run RAG models. The authors\\\\nwould also like to thank Kyunghyun Cho and Sewon Min for \u001b[0m\n",
       "\u001b[32mproductive discussions and advice. EP\\\\nthanks supports from the NSF Graduate Research Fellowship. PL is supported \u001b[0m\n",
       "\u001b[32mby the FAIR PhD\\\\nprogram.\\\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m.\\\\nRAG-Token\\\\nThe RAG-Token model can be seen as a standard, autoregressive seq2seq genera-\\\\ntor with transition\u001b[0m\n",
       "\u001b[32mprobability: p\\\\u2032\\\\n\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32myi|x, y1:i\\\\u22121\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = P\\\\nz\\\\u2208top-k\u001b[0m\u001b[32m(\u001b[0m\u001b[32mp\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\u00b7|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m p\\\\u03b7\u001b[0m\u001b[32m(\u001b[0m\u001b[32mzi|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32mp\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32myi|x, \u001b[0m\n",
       "\u001b[32mzi, y1:i\\\\u22121\u001b[0m\u001b[32m)\u001b[0m\u001b[32m To\\\\ndecode, we can plug p\\\\u2032\\\\n\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32myi|x, y1:i\\\\u22121\u001b[0m\u001b[32m)\u001b[0m\u001b[32m into a standard beam \u001b[0m\n",
       "\u001b[32mdecoder.\\\\nRAG-Sequence\\\\nFor RAG-Sequence, the likelihood p\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m does not break into a conventional per-\\\\ntoken \u001b[0m\n",
       "\u001b[32mlikelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for\\\\neach document z, \u001b[0m\n",
       "\u001b[32mscoring each hypothesis using p\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32myi|x, z, y1:i\\\\u22121\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. This yields a set of hypotheses\\\\nY , some of which \u001b[0m\n",
       "\u001b[32mmay not have appeared in the beams of all documents. To estimate the probability\\\\nof an hypothesis y we run an \u001b[0m\n",
       "\u001b[32madditional forward pass for each document z for which y does not\\\\nappear in the beam, multiply generator \u001b[0m\n",
       "\u001b[32mprobability with p\\\\u03b7\u001b[0m\u001b[32m(\u001b[0m\u001b[32mz|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and then sum the probabilities across\\\\nbeams for the marginals\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from \u001b[0m\n",
       "\u001b[32mRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . In one approach, RAG-Sequence, the model uses \u001b[0m\n",
       "\u001b[32mthe same document\\\\nto predict each target token. The second approach, RAG-Token, can predict each target token \u001b[0m\n",
       "\u001b[32mbased\\\\non a different document. In the following, we formally introduce both models and then describe \u001b[0m\n",
       "\u001b[32mthe\\\\np\\\\u03b7 and p\\\\u03b8 components, as well as the training and decoding \u001b[0m\n",
       "\u001b[32mprocedure.\\\\n2.1\\\\nModels\\\\nRAG-Sequence Model\\\\nThe RAG-Sequence model uses the same retrieved document to \u001b[0m\n",
       "\u001b[32mgenerate\\\\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable \u001b[0m\n",
       "\u001b[32mthat\\\\nis marginalized to get the seq2seq probability p\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m via a top-K approximation\\n'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">messages</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a document chatbot. Help the user as they ask questions about documents. User messaged</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">just asked: Tell me about RAG!\\n\\n From this, we have retrieved the following potentially-useful info:  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Conversation History Retrieval:\\n\\n\\n Document Retrieval:\\n[Quote from Retrieval-Augmented Generation for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge-Intensive NLP Tasks] . We refer to this decoding procedure as \\\\u201cThorough Decoding.\\\\u201d For </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">longer\\\\noutput sequences, |Y | can become large, requiring many forward passes. For more ef\\\\ufb01cient </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decoding,\\\\nwe can make a further approximation that p\\\\u03b8(y|x, zi) \\\\u22480 where y was not generated during </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">beam\\\\nsearch from x, zi. This avoids the need to run additional forward passes once the candidate set Y has\\\\nbeen</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generated. We refer to this decoding procedure as \\\\u201cFast Decoding.\\\\u201d\\\\n3\\\\nExperiments\\\\nWe experiment </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with RAG in a wide range of knowledge-intensive tasks. For all experiments, we use\\\\na single Wikipedia dump for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">our non-parametric knowledge source. Following Lee et al. [31] and\\\\nKarpukhin et al. [26], we use the December </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2018 dump. Each Wikipedia article is split into disjoint\\\\n100-word chunks, to make a total of 21M </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">documents\\n[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] . Since RAG can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">be\\\\nemployed as a language model, similar concerns as for GPT-2 [50] are valid here, although arguably\\\\nto a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lesser extent, including that it might be used to generate abuse, faked or misleading content in\\\\nthe news or on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">social media; to impersonate others; or to automate the production of spam/phishing\\\\ncontent [54]. Advanced </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language models may also lead to the automation of various jobs in the\\\\ncoming decades [16]. In order to mitigate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">these risks, AI systems could be employed to \\\\ufb01ght against\\\\nmisleading content and automated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">spam/phishing.\\\\nAcknowledgments\\\\nThe authors would like to thank the reviewers for their thoughtful and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">constructive feedback on this\\\\npaper, as well as HuggingFace for their help in open-sourcing code to run RAG </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models. The authors\\\\nwould also like to thank Kyunghyun Cho and Sewon Min for productive discussions and advice. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EP\\\\nthanks supports from the NSF Graduate Research Fellowship. PL is supported by the FAIR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">PhD\\\\nprogram.\\\\n\\n[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">.\\\\nRAG-Token\\\\nThe RAG-Token model can be seen as a standard, autoregressive seq2seq genera-\\\\ntor with transition</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probability: p\\\\u2032\\\\n\\\\u03b8(yi|x, y1:i\\\\u22121) = P\\\\nz\\\\u2208top-k(p(\\\\u00b7|x)) p\\\\u03b7(zi|x)p\\\\u03b8(yi|x, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">zi, y1:i\\\\u22121) To\\\\ndecode, we can plug p\\\\u2032\\\\n\\\\u03b8(yi|x, y1:i\\\\u22121) into a standard beam </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decoder.\\\\nRAG-Sequence\\\\nFor RAG-Sequence, the likelihood p(y|x) does not break into a conventional per-\\\\ntoken </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for\\\\neach document z, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scoring each hypothesis using p\\\\u03b8(yi|x, z, y1:i\\\\u22121). This yields a set of hypotheses\\\\nY , some of which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">may not have appeared in the beams of all documents. To estimate the probability\\\\nof an hypothesis y we run an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">additional forward pass for each document z for which y does not\\\\nappear in the beam, multiply generator </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probability with p\\\\u03b7(z|x) and then sum the probabilities across\\\\nbeams for the marginals\\n[Quote from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] . In one approach, RAG-Sequence, the model uses </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the same document\\\\nto predict each target token. The second approach, RAG-Token, can predict each target token </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">based\\\\non a different document. In the following, we formally introduce both models and then describe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\\\np\\\\u03b7 and p\\\\u03b8 components, as well as the training and decoding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">procedure.\\\\n2.1\\\\nModels\\\\nRAG-Sequence Model\\\\nThe RAG-Sequence model uses the same retrieved document to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generate\\\\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that\\\\nis marginalized to get the seq2seq probability p(y|x) via a top-K approximation\\n\\n\\n (Answer only from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieval. Only cite sources that are used. Make your response conversational.)'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tell me about RAG!'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={})</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ]</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33mmessages\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'You are a document chatbot. Help the user as they ask questions about documents. User messaged\u001b[0m\n",
       "\u001b[32mjust asked: Tell me about RAG!\\n\\n From this, we have retrieved the following potentially-useful info:  \u001b[0m\n",
       "\u001b[32mConversation History Retrieval:\\n\\n\\n Document Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Retrieval-Augmented Generation for \u001b[0m\n",
       "\u001b[32mKnowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . We refer to this decoding procedure as \\\\u201cThorough Decoding.\\\\u201d For \u001b[0m\n",
       "\u001b[32mlonger\\\\noutput sequences, |Y | can become large, requiring many forward passes. For more ef\\\\ufb01cient \u001b[0m\n",
       "\u001b[32mdecoding,\\\\nwe can make a further approximation that p\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x, zi\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\u22480 where y was not generated during \u001b[0m\n",
       "\u001b[32mbeam\\\\nsearch from x, zi. This avoids the need to run additional forward passes once the candidate set Y has\\\\nbeen\u001b[0m\n",
       "\u001b[32mgenerated. We refer to this decoding procedure as \\\\u201cFast Decoding.\\\\u201d\\\\n3\\\\nExperiments\\\\nWe experiment \u001b[0m\n",
       "\u001b[32mwith RAG in a wide range of knowledge-intensive tasks. For all experiments, we use\\\\na single Wikipedia dump for \u001b[0m\n",
       "\u001b[32mour non-parametric knowledge source. Following Lee et al. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m31\u001b[0m\u001b[32m]\u001b[0m\u001b[32m and\\\\nKarpukhin et al. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m26\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, we use the December \u001b[0m\n",
       "\u001b[32m2018 dump. Each Wikipedia article is split into disjoint\\\\n100-word chunks, to make a total of 21M \u001b[0m\n",
       "\u001b[32mdocuments\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . Since RAG can \u001b[0m\n",
       "\u001b[32mbe\\\\nemployed as a language model, similar concerns as for GPT-2 \u001b[0m\u001b[32m[\u001b[0m\u001b[32m50\u001b[0m\u001b[32m]\u001b[0m\u001b[32m are valid here, although arguably\\\\nto a \u001b[0m\n",
       "\u001b[32mlesser extent, including that it might be used to generate abuse, faked or misleading content in\\\\nthe news or on \u001b[0m\n",
       "\u001b[32msocial media; to impersonate others; or to automate the production of spam/phishing\\\\ncontent \u001b[0m\u001b[32m[\u001b[0m\u001b[32m54\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Advanced \u001b[0m\n",
       "\u001b[32mlanguage models may also lead to the automation of various jobs in the\\\\ncoming decades \u001b[0m\u001b[32m[\u001b[0m\u001b[32m16\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. In order to mitigate \u001b[0m\n",
       "\u001b[32mthese risks, AI systems could be employed to \\\\ufb01ght against\\\\nmisleading content and automated \u001b[0m\n",
       "\u001b[32mspam/phishing.\\\\nAcknowledgments\\\\nThe authors would like to thank the reviewers for their thoughtful and \u001b[0m\n",
       "\u001b[32mconstructive feedback on this\\\\npaper, as well as HuggingFace for their help in open-sourcing code to run RAG \u001b[0m\n",
       "\u001b[32mmodels. The authors\\\\nwould also like to thank Kyunghyun Cho and Sewon Min for productive discussions and advice. \u001b[0m\n",
       "\u001b[32mEP\\\\nthanks supports from the NSF Graduate Research Fellowship. PL is supported by the FAIR \u001b[0m\n",
       "\u001b[32mPhD\\\\nprogram.\\\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m.\\\\nRAG-Token\\\\nThe RAG-Token model can be seen as a standard, autoregressive seq2seq genera-\\\\ntor with transition\u001b[0m\n",
       "\u001b[32mprobability: p\\\\u2032\\\\n\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32myi|x, y1:i\\\\u22121\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = P\\\\nz\\\\u2208top-k\u001b[0m\u001b[32m(\u001b[0m\u001b[32mp\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\u00b7|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m p\\\\u03b7\u001b[0m\u001b[32m(\u001b[0m\u001b[32mzi|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32mp\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32myi|x, \u001b[0m\n",
       "\u001b[32mzi, y1:i\\\\u22121\u001b[0m\u001b[32m)\u001b[0m\u001b[32m To\\\\ndecode, we can plug p\\\\u2032\\\\n\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32myi|x, y1:i\\\\u22121\u001b[0m\u001b[32m)\u001b[0m\u001b[32m into a standard beam \u001b[0m\n",
       "\u001b[32mdecoder.\\\\nRAG-Sequence\\\\nFor RAG-Sequence, the likelihood p\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m does not break into a conventional per-\\\\ntoken \u001b[0m\n",
       "\u001b[32mlikelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for\\\\neach document z, \u001b[0m\n",
       "\u001b[32mscoring each hypothesis using p\\\\u03b8\u001b[0m\u001b[32m(\u001b[0m\u001b[32myi|x, z, y1:i\\\\u22121\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. This yields a set of hypotheses\\\\nY , some of which \u001b[0m\n",
       "\u001b[32mmay not have appeared in the beams of all documents. To estimate the probability\\\\nof an hypothesis y we run an \u001b[0m\n",
       "\u001b[32madditional forward pass for each document z for which y does not\\\\nappear in the beam, multiply generator \u001b[0m\n",
       "\u001b[32mprobability with p\\\\u03b7\u001b[0m\u001b[32m(\u001b[0m\u001b[32mz|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and then sum the probabilities across\\\\nbeams for the marginals\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from \u001b[0m\n",
       "\u001b[32mRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . In one approach, RAG-Sequence, the model uses \u001b[0m\n",
       "\u001b[32mthe same document\\\\nto predict each target token. The second approach, RAG-Token, can predict each target token \u001b[0m\n",
       "\u001b[32mbased\\\\non a different document. In the following, we formally introduce both models and then describe \u001b[0m\n",
       "\u001b[32mthe\\\\np\\\\u03b7 and p\\\\u03b8 components, as well as the training and decoding \u001b[0m\n",
       "\u001b[32mprocedure.\\\\n2.1\\\\nModels\\\\nRAG-Sequence Model\\\\nThe RAG-Sequence model uses the same retrieved document to \u001b[0m\n",
       "\u001b[32mgenerate\\\\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable \u001b[0m\n",
       "\u001b[32mthat\\\\nis marginalized to get the seq2seq probability p\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m via a top-K approximation\\n\\n\\n \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAnswer only from \u001b[0m\n",
       "\u001b[32mretrieval. Only cite sources that are used. Make your response conversational.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Tell me about RAG!'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG stands for Retrieval-Augmented Generation. It is a method that combines a retriever model, which identifies relevant documents from a large corpus, with a generator model, which produces answers to natural language processing (NLP) tasks. The retriever model is based on the DPR (Dense Passage Retrieval) model, and the generator model is based on a transformer model.\n",
      "\n",
      "RAG can be employed in a variety of knowledge-intensive NLP tasks and is trained on a single Wikipedia dump, which is split into disjoint 100-word chunks to make a total of 21M documents.\n",
      "\n",
      "There are two ways that RAG can be used, RAG-Sequence and RAG-Token. RAG-Sequence uses the same document to predict each target token, while RAG-Token can predict each target token based on a different document.\n",
      "\n",
      "There are also two decoding procedures that can be used with RAG, Thorough Decoding and Fast Decoding. Thorough decoding runs additional forward passes for longer output sequences, while Fast Decoding makes an approximation that p(y|x,zi) â‰ˆ 0 where y was not generated during the beam search from x, zi. This avoids the need to run additional forward passes once the candidate set Y has been generated.\n",
      "\n",
      "It's important to note that similar concerns to GPT-2 apply to RAG, including the potential for misuse in generating abuse, faked or misleading content, impersonating others and automating the production of spam/phishing content.\n",
      "Therefore, AI systems should be employed to fight against misleading content and automated spam/phishing.\n",
      "\n",
      "The RAG model was introduced in the paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" (Lewis, Linford, et.al, 2020) and the documentation provided is from that paper.\n",
      "\n",
      "\n",
      "References:\n",
      "- Lewis, Parker, et al. \"Retrieval-augmented generation for knowledge-intensive nlp tasks.\" arXiv preprint arXiv:2002.08913 (2020).\n",
      "- Radford, Alec, et al. \"Language models are unsupervised multitask learners.\" OpenAI blog 1.8 (2019): 9.\n",
      "- Karpukhin, Vsevolod, et al. \"Dense Passage Retrieval for Open-Domain Question Answering.\" arXiv preprint arXiv:2004.04906 (2020)."
     ]
    }
   ],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import gradio as gr\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")\n",
    "# instruct_llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")\n",
    "\n",
    "convstore = default_FAISS()\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([\n",
    "        f\"User previously responded with {d.get('input')}\",\n",
    "        f\"Agent previously responded with {d.get('output')}\"\n",
    "    ])\n",
    "    return d.get('output')\n",
    "\n",
    "initial_msg = (\n",
    "    \"Hello! I am a document chat agent here to help the user!\"\n",
    "    f\" I have access to the following documents: {doc_string}\\n\\nHow can I help you?\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\",\n",
    "    \"You are a document chatbot. Help the user as they ask questions about documents.\"\n",
    "    \" User messaged just asked: {input}\\n\\n\"\n",
    "    \" From this, we have retrieved the following potentially-useful info: \"\n",
    "    \" Conversation History Retrieval:\\n{history}\\n\\n\"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational.)\"\n",
    "), ('user', '{input}')])\n",
    "\n",
    "stream_chain = chat_prompt| RPrint() | instruct_llm | StrOutputParser()\n",
    "\n",
    "################################################################################################\n",
    "## BEGIN TODO: Implement the retrieval chain to make your system work!\n",
    "\n",
    "\n",
    "retrieval_chain = (\n",
    "    {'input' : (lambda x: x)}\n",
    "    ## TODO: Make sure to retrieve history & context from convstore & docstore, respectively.\n",
    "    ## HINT: Our solution uses RunnableAssign, itemgetter, long_reorder, and docs2str\n",
    "    | RunnableAssign({'history' : itemgetter('input') | convstore.as_retriever() | long_reorder | docs2str})\n",
    "    | RunnableAssign({'context' : itemgetter('input') | docstore.as_retriever()  | long_reorder | docs2str})\n",
    "    | RPrint()\n",
    ")\n",
    "\n",
    "## END TODO\n",
    "################################################################################################\n",
    "def chat_gen(message, history=[], return_buffer=True):\n",
    "    buffer = \"\"\n",
    "    ## First perform the retrieval based on the input message\n",
    "    retrieval = retrieval_chain.invoke(message)\n",
    "    line_buffer = \"\"\n",
    "\n",
    "    ## Then, stream the results of the stream_chain\n",
    "    for token in stream_chain.stream(retrieval):\n",
    "        buffer += token\n",
    "        ## If you're using standard print, keep line from getting too long\n",
    "        yield buffer if return_buffer else token\n",
    "\n",
    "    ## Lastly, save the chat exchange to the conversation memory buffer\n",
    "    save_memory_and_get_output({'input':  message, 'output': buffer}, convstore)\n",
    "\n",
    "\n",
    "## Start of Agent Event Loop\n",
    "test_question = \"Tell me about RAG!\"  ## <- modify as desired\n",
    "\n",
    "## Before you launch your gradio interface, make sure your thing works\n",
    "for response in chat_gen(test_question, return_buffer=False):\n",
    "    print(response, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9W7sC5Z6BfqM",
   "metadata": {
    "id": "9W7sC5Z6BfqM"
   },
   "source": [
    "### **ä»»å‹™ 4ï¼š**Â èˆ‡æ‚¨çš„ Gradio èŠå¤©æ©Ÿå™¨äººäº’å‹•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fMP3l7QL2JWT",
   "metadata": {
    "id": "fMP3l7QL2JWT"
   },
   "outputs": [],
   "source": [
    "# chatbot = gr.Chatbot(value = [[None, initial_msg]])\n",
    "# demo = gr.ChatInterface(chat_gen, chatbot=chatbot).queue()\n",
    "\n",
    "# try:\n",
    "#     demo.launch(debug=True, share=True, show_api=False)\n",
    "#     demo.close()\n",
    "# except Exception as e:\n",
    "#     demo.close()\n",
    "#     print(e)\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCb3RVVfbmQ0",
   "metadata": {
    "id": "yCb3RVVfbmQ0"
   },
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬å››éƒ¨åˆ†ï¼š**Â ç‚ºè©•é‡(Assessment)ä¿å­˜æ‚¨çš„ç´¢å¼•\n",
    "\n",
    "\n",
    "åœ¨æ‚¨å¯¦ä½œäº† RAG éˆ(Chain)ä¹‹å¾Œï¼Œè«‹å¦‚Â [å®˜æ–¹æ–‡ä»¶](https://python.langchain.com/docs/integrations/vectorstores/faiss#saving-and-loading)Â æ‰€ç¤ºä¿å­˜æ‚¨ç´¯ç©çš„å‘é‡å­˜å„²åº«(Vector Store)ã€‚æ‚¨å°‡æœ‰æ©Ÿæœƒåœ¨æœ€çµ‚è©•é‡(Assessment)ä¸­å†æ¬¡ä½¿ç”¨å®ƒï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Y4se5wQ4Afda",
   "metadata": {
    "id": "Y4se5wQ4Afda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docstore_index/\n",
      "docstore_index/index.pkl\n",
      "docstore_index/index.faiss\n"
     ]
    }
   ],
   "source": [
    "## Save and compress your index\n",
    "docstore.save_local(\"docstore_index\")\n",
    "!tar czvf docstore_index.tgz docstore_index\n",
    "\n",
    "!rm -rf docstore_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LsI7NivbIgFw",
   "metadata": {
    "id": "LsI7NivbIgFw"
   },
   "source": [
    "\n",
    "å¦‚æœä¸€åˆ‡éƒ½æ­£ç¢ºä¿å­˜ï¼Œå¯ä»¥invokeä»¥ä¸‹è¡Œå¾å£“ç¸®çš„Â `tgz`Â æª”æ¡ˆä¸­æ‹‰å–ç´¢å¼•ï¼ˆå‡è¨­å·²å®‰è£ pip è¦æ±‚ï¼‰ã€‚åœ¨æ‚¨ç¢ºèªç¨‹å¼ç¢¼å€å¡Š(Cell)å¯ä»¥æ‹‰å…¥æ‚¨çš„ç´¢å¼•å¾Œï¼Œä¸‹è¼‰Â `docstore_index.tgz`Â ä»¥åœ¨æœ€å¾Œä¸€å€‹ notebook ä¸­ä½¿ç”¨ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Qs8820ucIu1t",
   "metadata": {
    "id": "Qs8820ucIu1t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docstore_index/\n",
      "docstore_index/index.pkl\n",
      "docstore_index/index.faiss\n",
      ". To demonstrate, we build an index using the DrQA [5]\\nWikipedia dump from December 2016 and compare outputs from RAG using this index to the newer\\nindex from our main results (December 2018). We prepare a list of 82 world leaders who had changed\\n7\\nTable 4: Human assessments for the Jeopardy\\nQuestion Generation Task.\\nFactuality\\nSpeci\\ufb01city\\nBART better\\n7.1%\\n16.8%\\nRAG better\\n42.7%\\n37.4%\\nBoth good\\n11.7%\\n11.8%\\nBoth poor\\n17.7%\\n6.9%\\nNo majority\\n20.8%\\n20.1%\\nTable 5: Ratio of distinct to total tri-grams for\\ngeneration tasks.\\nMSMARCO\\nJeopardy QGen\\nGold\\n89.6%\\n90.0%\\nBART\\n70.7%\\n32.4%\\nRAG-Token\\n77.8%\\n46.8%\\nRAG-Seq.\\n83.5%\\n53.8%\\nTable 6: Ablations on the dev set. As FEVER is a classi\\ufb01cation task, both RAG models are equivalent.\\nModel\\nNQ\\nTQA\\nWQ\\nCT\\nJeopardy-QGen\\nMSMarco\\nFVR-3\\nFVR-2\\nExact Match\\nB-1\\nQB-1\\nR-L\\nB-1\\nLabel Accuracy\\nRAG-Token-BM25\\n29.7\\n41.5\\n32.1\\n33.1\\n17.5\\n22.3\\n55.5\\n48.4\\n75.1\\n91.6\\nRAG-Sequence-BM25\\n31.8\\n44.1\\n36.6\\n33\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "!tar xzvf docstore_index.tgz\n",
    "new_db = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "docs = new_db.similarity_search(\"Testing the index\")\n",
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "as_3vWJGKB2F",
   "metadata": {
    "id": "as_3vWJGKB2F"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬äº”éƒ¨åˆ†ï¼š**Â ç¸½çµ\n",
    "\n",
    "\n",
    "æ­å–œï¼å‡è¨­æ‚¨çš„ RAG éˆ(Chain)ä¸€åˆ‡é †åˆ©ï¼Œæ‚¨ç¾åœ¨æº–å‚™å¥½é€²å…¥Â **RAG è©•é‡(Assessment) [è©•é‡(Assessment)]**Â éƒ¨åˆ†ï¼\n",
    "\n",
    "<font color=\"#76b900\">**åšå¾—å¾ˆå¥½ï¼**</font>\n",
    "\n",
    "### **ä¸‹ä¸€æ­¥ï¼š**\n",
    "\n",
    "\n",
    "1.  **[å¯é¸]**Â é‡æ–°è¨ªå•(Navigate) notebook é ‚éƒ¨çš„**ã€Œå€¼å¾—æ€è€ƒçš„å•é¡Œã€éƒ¨åˆ†**ï¼Œä¸¦æ€è€ƒä¸€äº›å¯èƒ½çš„ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098de2f-32b3-428e-8f3b-f54141ec40b4",
   "metadata": {
    "id": "8098de2f-32b3-428e-8f3b-f54141ec40b4"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
